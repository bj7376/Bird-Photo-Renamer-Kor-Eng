# íŒŒì¼ ì´ë¦„: core_logic.py (v2.0 ìµœì¢…) - ë¦¬í¬íŠ¸ ë²„ê·¸ ìˆ˜ì •
from __future__ import annotations

import json
import os
import re
import shutil
import time
from datetime import datetime
from typing import Dict, List

import pandas as pd
from PIL import Image

# ---------------------- ìœ í‹¸ë¦¬í‹° ----------------------

def sanitize_filename(name: str) -> str:
    if not isinstance(name, str):
        return ""
    name = name.replace('*', '')
    name = re.sub(r'[\\/:"*?<>|]', '', name).strip()
    return re.sub(r"\s+", "_", name)


def get_photo_datetime(img: Image.Image):
    try:
        exif = img._getexif()
        if not exif:
            return None
        ds = exif.get(36867) or exif.get(306)
        return datetime.strptime(ds, "%Y:%m:%d %H:%M:%S") if ds else None
    except Exception:
        return None

# ------------------ ì™¸ë¶€ ë°ì´í„° ì¡°íšŒ ------------------

def wiki_lookup(wiki, common: str | None, sci: str | None, log):
    if not common:
        return None
    log(f"  - Wikipediaì—ì„œ '{common}' ê²€ìƒ‰ ì¤‘...")
    page = wiki.page(common)
    if not page.exists() and sci:
        log(f"  - ì˜ë¬¸ëª… ì‹¤íŒ¨, í•™ëª… '{sci}'ë¡œ ì¬ê²€ìƒ‰...")
        page = wiki.page(sci)
    if page.exists():
        en = page.title
        ko = page.langlinks.get('ko').title if page.langlinks and 'ko' in page.langlinks else f"*{en}"
        log(f"  - Wikipedia ì°¾ìŒ: {ko} | {en}")
        return {"korean_name": ko, "common_name": en}
    log("  - Wikipedia ê²°ê³¼ ì—†ìŒ.")
    return None


def csv_lookup(csv_df: pd.DataFrame | None, sci: str | None, log):
    if csv_df is None or not sci:
        return None
    
    try:
        if "í•™ëª…" in csv_df.columns and "êµ­ëª…" in csv_df.columns:
            mask = csv_df["í•™ëª…"].str.strip().str.lower() == sci.strip().lower()
            if mask.any():
                ko = csv_df.loc[mask, "êµ­ëª…"].iloc[0]
                log("  - CSV ì¼ì¹˜ í•­ëª© ë°œê²¬! (ì»¬ëŸ¼ëª… ë°©ì‹)")
                return {"korean_name": ko}
        
        elif len(csv_df.columns) >= 3:
            sci_col = csv_df.iloc[:, 2].astype(str).str.strip().str.lower()
            mask = sci_col == sci.strip().lower()
            if mask.any():
                ko = csv_df.iloc[mask.idxmax(), 1]
                log("  - CSV ì¼ì¹˜ í•­ëª© ë°œê²¬! (ì¸ë±ìŠ¤ ë°©ì‹)")
                return {"korean_name": ko}
        
        log(f"  - CSVì—ì„œ '{sci}' ì°¾ì§€ ëª»í•¨")
        return None
        
    except Exception as e:
        log(f"  - CSV ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return None

# -------------- ì´ë¦„ ë³´ì™„(ìœ„í‚¤â†’CSVâ†’Gemini) --------------

def resolve_names(res: Dict, wiki_info, csv_df, log):
    common = res.get('common_name') or 'N/A'
    sci    = res.get('scientific_name') or 'N/A'
    order  = res.get('order')  or 'N/A'
    family = res.get('family') or 'N/A'
    korean = 'N/A'; src = 'N/A'; csv_used = False

    if wiki_info:
        common = wiki_info.get('common_name', common)
        korean = wiki_info.get('korean_name', korean)
        src = 'Wikipedia'
        
        if korean.startswith('*'):
            log("  - Wikipedia í•œêµ­ëª… ì—†ìŒ, CSV ë³´ì™„ ì‹œë„...")
            csv_info = csv_lookup(csv_df, sci, log)
            if csv_info:
                korean = csv_info['korean_name']
                src = 'Wikipedia+CSV'
                csv_used = True
    
    if not wiki_info or korean == 'N/A' or korean.startswith('*'):
        log("  - CSVì—ì„œ ì§ì ‘ ì¡°íšŒ...")
        csv_info = csv_lookup(csv_df, sci, log)
        if csv_info:
            korean = csv_info['korean_name']
            if not wiki_info:
                src = 'CSV'
            else:
                src = 'CSV (Wikipedia ë³´ì™„)'
            csv_used = True

    if korean == 'N/A' or korean.startswith('*'):
        korean = f"*{common}" if common != 'N/A' else 'ë¯¸ì‹ë³„'
        if src == 'N/A':
            src = 'Gemini (ê²€ì¦ ì‹¤íŒ¨)'
        else:
            src += ' (êµ­ëª… ë¯¸í™•ì¸)'
    
    return korean, common, sci, order, family, src, csv_used

# --------------------- í¬ë¡­ ì´ë¯¸ì§€ ì €ì¥ ---------------------

def save_cropped_images(observations: List[Dict], yolo, out_dir: str, crop_dir: str, log):
    """í¬ë¡­ëœ ì¡°ë¥˜ ì´ë¯¸ì§€ë“¤ì„ ë³„ë„ ì €ì¥"""
    if not observations:
        return
    
    os.makedirs(crop_dir, exist_ok=True)
    log(f"  - í¬ë¡­ëœ ì´ë¯¸ì§€ ì €ì¥ ì¤‘... ({crop_dir})")
    
    saved_count = 0
    
    # [ìˆ˜ì •ë¨] ì¢…ë³„ì´ ì•„ë‹Œ ê´€ì°°ë³„ë¡œ í¬ë¡­ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    for obs_data in observations:
        new_filename = obs_data['new_filename']
        
        # ì²˜ë¦¬ëœ í´ë”ì—ì„œ ì›ë³¸ ì´ë¯¸ì§€ ì°¾ê¸°
        src_path = os.path.join(out_dir, new_filename)
        
        if not os.path.exists(src_path):
            log(f"    - íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {new_filename}")
            continue
            
        # [ìˆ˜ì •ë¨] í¬ë¡­ íŒŒì¼ëª…ì„ ì›ë³¸ íŒŒì¼ëª… ê¸°ë°˜ìœ¼ë¡œ ê³ ìœ í•˜ê²Œ ìƒì„±
        base_name = os.path.splitext(new_filename)[0]
        crop_filename = f"{base_name}_crop.jpg"
        crop_path = os.path.join(crop_dir, crop_filename)
        
        # ì´ë¯¸ í¬ë¡­ íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ê±´ë„ˆë›°ê¸°
        if os.path.exists(crop_path):
            continue

        try:
            # YOLOë¡œ ë‹¤ì‹œ íƒì§€í•´ì„œ í¬ë¡­
            results = yolo(src_path, verbose=False)
            birds = [{'box': b.xyxy[0].cpu().numpy(), 'conf': float(b.conf[0])} 
                    for b in results[0].boxes 
                    if yolo.names[int(b.cls[0])] == 'bird' and float(b.conf[0]) >= 0.25]
            
            if birds:
                best_bird = max(birds, key=lambda x: x['conf'])
                
                with Image.open(src_path) as img:
                    crop = img.crop(tuple(best_bird['box']))
                    # ì ì ˆí•œ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                    crop.thumbnail((512, 512), Image.Resampling.LANCZOS)
                    crop.save(crop_path, 'JPEG', quality=90)
                
                saved_count += 1
                log(f"    - ì €ì¥: {crop_filename}")
            else:
                log(f"    - ìƒˆ íƒì§€ ì‹¤íŒ¨: {new_filename}")
                
        except Exception as e:
            log(f"    - í¬ë¡­ ì‹¤íŒ¨ ({new_filename}): {e}")
    
    log(f"  - í¬ë¡­ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {saved_count}ê°œ")

# --------------------- ë¡œê·¸ ìƒì„± ---------------------

def create_logs(log_dir: str, obs: List[Dict], src_dir: str, log):
    if not obs:
        log("- ë¡œê·¸ë¥¼ ìƒì„±í•  ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    os.makedirs(log_dir, exist_ok=True)
    uniq = {o['scientific_name'] for o in obs if o['scientific_name'] != 'N/A'}

    # ì‹œê°„ìˆœ ë¡œê·¸
    with open(os.path.join(log_dir,'log_chronological.txt'),'w',encoding='utf-8') as f:
        f.write('='*50+'\nì‹œê°„ìˆœ ìë™ íƒì¡° ê¸°ë¡\n'+'='*50+'\n')
        f.write(f"ê¸°ë¡ ìƒì„±: {datetime.now():%Y-%m-%d %H:%M:%S}\nëŒ€ìƒ í´ë”: {os.path.abspath(src_dir)}\n")
        f.write(f"ì²˜ë¦¬ ì‚¬ì§„: {len(obs)}ê°œ\nê´€ì°° ì¢…: {len(uniq)}ì¢…\n"+'='*50+'\n\n')
        for o in obs:
            ts = o['datetime'].strftime('%Y-%m-%d %H:%M:%S') if o['datetime'] else 'ì‹œê°„ ì •ë³´ ì—†ìŒ'
            f.write(f"â–¶ {ts}\n  - êµ­ëª…: {o['korean_name']}\n  - ì˜ë¬¸ëª…: {o['common_name']}\n  - í•™ëª…: {o['scientific_name']}\n  - ë¶„ë¥˜: {o['taxonomy_str']}\n  - íŒŒì¼: {o['new_filename']}\n"+'-'*50+'\n')

    # ë¶„ë¥˜í•™ì  ì²´í¬ë¦¬ìŠ¤íŠ¸
    uniq_map = {o['scientific_name']:o for o in obs if o['scientific_name']!='N/A'}
    sorted_obs = sorted(uniq_map.values(), key=lambda x:(x['taxonomy'].get('order','zzz'),x['taxonomy'].get('family','zzz')))
    with open(os.path.join(log_dir,'log_taxonomic.txt'),'w',encoding='utf-8') as f:
        f.write('='*50+'\në¶„ë¥˜í•™ì  ì²´í¬ë¦¬ìŠ¤íŠ¸\n'+'='*50+'\n')
        f.write(f"ê¸°ë¡ ìƒì„±: {datetime.now():%Y-%m-%d %H:%M:%S}\nì´ ì¢…ìˆ˜: {len(sorted_obs)}ì¢…\n"+'='*50+'\n')
        cur_order=cur_family=''
        for o in sorted_obs:
            order=o['taxonomy'].get('order','ì •ë³´ ì—†ìŒ'); family=o['taxonomy'].get('family','ì •ë³´ ì—†ìŒ')
            if order!=cur_order: cur_order=order; f.write(f"\n[ëª©] {order}\n"); cur_family=''
            if family!=cur_family: cur_family=family; f.write(f"  [ê³¼] {family}\n")
            f.write(f"    - {o['korean_name']} ({o['common_name']})\n")
    
    log("  - í…ìŠ¤íŠ¸ ë¡œê·¸ íŒŒì¼ ìƒì„± ì™„ë£Œ.")

# -------------------- ë©”ì¸ í•¨ìˆ˜ --------------------

def process_all_images(cfg: Dict):
    log      = cfg['log_callback']
    yolo     = cfg['yolo_model']
    gemini   = cfg['gemini_model']
    wiki     = cfg['wiki_wiki']
    csv_df   = cfg.get('csv_db')
    report_options = cfg.get('report_options', {})
    is_pro_mode = cfg.get('is_pro_mode', False)

    src_dir  = cfg['target_folder']
    out_dir  = os.path.join(src_dir,'processed_birds_final')
    os.makedirs(out_dir, exist_ok=True)
    log_dir  = os.path.join(out_dir,'íƒì¡°ê¸°ë¡')

    RESIZE=(768,768); CONF=0.25; DELAY=2 # API ë”œë ˆì´ ì†Œí­ ê°ì†Œ
    RAW_EXT=('.orf','.cr2','.cr3','.nef','.arw','.dng','.raf','.rw2')

    observations=[]
    log(f"ëŒ€ìƒ: {os.path.abspath(src_dir)} â†’ ì¶œë ¥: {os.path.abspath(out_dir)}")
    
    if is_pro_mode:
        log("ğŸ”¥ í”„ë¦¬ë¯¸ì—„ ëª¨ë“œ í™œì„±í™”: Gemini 2.5 Pro ì‚¬ìš©")
        log("  - ì´ˆë³´ íƒì¡°ì¸ ìˆ˜ì¤€ì˜ ì¡°ë¥˜ ì‹ë³„ ì •í™•ë„")
        log("  - ë‹¨ì¼ ì´ë¯¸ì§€ ìµœì í™” ì²˜ë¦¬")
    else:
        log("ê¸°ë³¸ ëª¨ë“œ: Gemini 2.0 Flash ì‚¬ìš©")
    
    if csv_df is not None:
        log(f"CSV ë°ì´í„°ë² ì´ìŠ¤: í™œì„±í™” ({len(csv_df)}ê°œ ë ˆì½”ë“œ)")
    else:
        log("CSV ë°ì´í„°ë² ì´ìŠ¤: ë¹„í™œì„±í™”")

    # ì´ë¯¸ì§€ ì²˜ë¦¬
    image_files = [f for f in os.listdir(src_dir) if f.lower().endswith(('.jpg', '.jpeg'))]
    total_files = len(image_files)
    
    for i, fname in enumerate(image_files):
        src_path=os.path.join(src_dir,fname)
        log(f"\n- [{i+1}/{total_files}] {fname} ì²˜ë¦¬ ì¤‘")
        
        try:
            yres=yolo(src_path,verbose=False)
            birds=[{'box':b.xyxy[0].cpu().numpy(),'conf':float(b.conf[0])} for b in yres[0].boxes if yolo.names[int(b.cls[0])]=='bird' and float(b.conf[0])>=CONF]
            if not birds: 
                log("  - ìƒˆ ì—†ìŒ")
                continue
            
            best=max(birds,key=lambda x:x['conf'])
            log(f"  - ìƒˆ íƒì§€! ({best['conf']:.2f})")
            
            with Image.open(src_path) as im:
                dt=get_photo_datetime(im)
                crop=im.crop(tuple(best['box'])).resize(RESIZE)
            
            if dt:
                month_day = dt.strftime("%B %d")
                date_context = f" on {month_day}"
                seasonal_hint = f" Consider the seasonal migration patterns and breeding cycles typical for this time of year ({month_day})."
            else:
                date_context = ""
                seasonal_hint = ""
            
            # í”„ë¡¬í”„íŠ¸ëŠ” ëª¨ë“œì— ìƒê´€ì—†ì´ ë™ì¼í•˜ê²Œ ìƒì„±
            prompt_with_date = (f"Act as an expert ornithologist specializing in the avifauna of {cfg['photo_location']}. "
                              f"The following is a cropped image of a bird taken in {cfg['photo_location']}{date_context}."
                              f"{seasonal_hint} "
                              "Respond in JSON with 'common_name','scientific_name','order','family'. If uncertain set nulls.")

            if is_pro_mode:
                log("  - Gemini 2.5 Pro ë¶„ì„ ìš”ì²­... (í”„ë¦¬ë¯¸ì—„)")
            else:
                log("  - Gemini 2.0 Flash ë¶„ì„ ìš”ì²­... (ê¸°ë³¸)")

            # API í˜¸ì¶œì€ ë‹¨ì¼ ì´ë¯¸ì§€ë¡œ í†µì¼ (ë‹¤ì¤‘ ì´ë¯¸ì§€ variationì€ ì˜¤ë¥˜ ê°€ëŠ¥ì„± ì¡´ì¬)
            response = gemini.generate_content(
                [prompt_with_date, crop],
                generation_config={"response_mime_type": "application/json"}
            )
            if is_pro_mode: log("ë”œë ˆì´ ì—†ì´ API ì¦‰ì‹œ í˜¸ì¶œ...")
            else:
                log(f"  - API ë”œë ˆì´ ({DELAY}ì´ˆ)...")
                time.sleep(DELAY)

            res = json.loads(response.text)
            
            gemini_common = res.get('common_name')
            gemini_sci = res.get('scientific_name')
            
            if not gemini_common and not gemini_sci:
                log("  - Gemini ì‹ë³„ ì‹¤íŒ¨")
                continue
            
            wiki_info = wiki_lookup(wiki, gemini_common, gemini_sci, log)
            korean, common, sci, order, family, src, csv_used = resolve_names(res, wiki_info, csv_df, log)
            
            log(f"  - ìµœì¢… ì¶œì²˜: {src}")
            log(f"  - ìµœì¢… ê²°ê³¼: {korean} | {common} ({sci})")
            
            taxonomy_str = f"ëª©: {order}, ê³¼: {family}"
            taxonomy_dict = {"order": order, "family": family}
            
        except Exception as e:
            log(f"  ! ë¶„ì„ ì˜¤ë¥˜: {e}")
            continue
        
        try:
            # íŒŒì¼ëª… ìƒì„± ë° ì €ì¥
            date_prefix = dt.strftime('%Y%m%d_%H%M%S_') if dt else ""
            if not korean.startswith('*'):
                base_name = f"{date_prefix}{sanitize_filename(korean)}_{sanitize_filename(common)}"
            else:
                base_name = f"{date_prefix}{sanitize_filename(common)}"
            
            new_fname = f"{base_name}.jpg"
            new_path = os.path.join(out_dir, new_fname)
            
            # ì¤‘ë³µ ë°©ì§€
            counter = 1
            while os.path.exists(new_path):
                new_fname = f"{base_name}_{counter}.jpg"
                new_path = os.path.join(out_dir, new_fname)
                counter += 1
            
            # JPG ë³µì‚¬
            shutil.copy2(src_path, new_path)
            log(f"  >> JPG ì €ì¥: {new_fname}")
            
            # RAW íŒŒì¼ ì°¾ì•„ì„œ ë³µì‚¬
            base_fname = os.path.splitext(fname)[0]
            for ext in RAW_EXT:
                raw_path = os.path.join(src_dir, f"{base_fname}{ext}")
                if os.path.exists(raw_path):
                    raw_new_name = f"{os.path.splitext(new_fname)[0]}{ext}"
                    raw_new_path = os.path.join(out_dir, raw_new_name)
                    shutil.copy2(raw_path, raw_new_path)
                    log(f"  >> RAW ì €ì¥: {raw_new_name}")
                    break
            
            # ê´€ì°° ê¸°ë¡ ì¶”ê°€
            observations.append({
                'datetime': dt,
                'new_filename': new_fname,
                'common_name': common,
                'korean_name': korean,
                'scientific_name': sci,
                'taxonomy': taxonomy_dict,
                'taxonomy_str': taxonomy_str,
                'csv_used': csv_used
            })
            
        except Exception as e:
            log(f"  ! íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
    
    # ==================== v2.0 ì‹œê°ì  ë¦¬í¬íŠ¸ ====================
    
    if observations and report_options.get('format') != 'none':
        log(f"\nğŸ¨ ì‹œê°ì  ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        
        # í¬ë¡­ëœ ì´ë¯¸ì§€ ì €ì¥
        if report_options.get('save_crops', True):
            crop_dir = os.path.join(out_dir, 'cropped_images')
            log("- í¬ë¡­ëœ ì¡°ë¥˜ ì´ë¯¸ì§€ ì €ì¥ ì¤‘...")
            save_cropped_images(observations, yolo, out_dir, crop_dir, log)
        
        try:
            import visual_report
            visual_report.create_visual_reports(observations, out_dir, src_dir, report_options, cfg['photo_location'], log)
        except ImportError:
            log("  - visual_report.py ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œê°ì  ë¦¬í¬íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        except Exception as e:
            log(f"  - ì‹œê°ì  ë¦¬í¬íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
    
    # ê¸°ì¡´ í…ìŠ¤íŠ¸ ë¡œê·¸ ìƒì„±
    create_logs(log_dir, observations, src_dir, log)
    
    # ìµœì¢… í†µê³„
    csv_count = sum(1 for o in observations if o.get('csv_used'))
    unique_species = len(set(o['scientific_name'] for o in observations if o['scientific_name'] != 'N/A'))
    
    log(f"\nğŸ‰ ì²˜ë¦¬ ì™„ë£Œ!")
    if is_pro_mode:
        log(f"  - ì‚¬ìš© ëª¨ë“œ: í”„ë¦¬ë¯¸ì—„ (Gemini 2.5 Pro)")
    else:
        log(f"  - ì‚¬ìš© ëª¨ë“œ: ê¸°ë³¸ (Gemini 2.0 Flash)")
    log(f"  - ì´ ì²˜ë¦¬: {len(observations)}ê°œ")
    log(f"  - CSV í™œìš©: {csv_count}ê°œ") 
    log(f"  - ê³ ìœ  ì¢…: {unique_species}ì¢…")
    
    if observations:
        log(f"\nğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤:")
        log(f"  - ì²˜ë¦¬ëœ ì‚¬ì§„: {out_dir}")
        log(f"  - íƒì¡° ê¸°ë¡: {log_dir}")
        
        if report_options.get('format') != 'none':
            crop_dir = os.path.join(out_dir, 'cropped_images')
            if report_options.get('save_crops', True):
                log(f"  - í¬ë¡­ ì´ë¯¸ì§€: {crop_dir}")
            
            report_format = report_options.get('format', 'html')
            if report_format in ['html', 'both']:
                log(f"  - HTML ë¦¬í¬íŠ¸: {os.path.join(log_dir, 'visual_report.html')}")
            if report_format in ['docx', 'both']:
                log(f"  - Word ë¦¬í¬íŠ¸: {os.path.join(log_dir, 'visual_report.docx')}")
            
            log(f"\nğŸ’¡ HTML ë¦¬í¬íŠ¸ëŠ” ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ, Word ë¦¬í¬íŠ¸ëŠ” Microsoft Wordì—ì„œ ì—´ì–´ë³´ì„¸ìš”!")
    else:
        log(f"\nâš ï¸  ì²˜ë¦¬ëœ ì¡°ë¥˜ ì‚¬ì§„ì´ ì—†ìŠµë‹ˆë‹¤.")